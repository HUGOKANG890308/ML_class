{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, fbeta_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=1000, n_classes=2, weights=[\n",
    "                           0.9, 0.1], random_state=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=1)\n",
    "X_train=pd.DataFrame(X_train)\n",
    "X_val=pd.DataFrame(X_val)\n",
    "X_test=pd.DataFrame(X_test)\n",
    "y_train=pd.DataFrame(y_train)\n",
    "y_val=pd.DataFrame(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_1860\\4208077023.py:40: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  model  accuracy  f1_score  precision  recall     auc  f_beta\n",
      "0   xgb     0.915    0.6047     0.8125  0.4815  0.7321  0.5019\n",
      "1    rf     0.905    0.5128     0.8333  0.3704  0.6794  0.3922\n"
     ]
    }
   ],
   "source": [
    "def evaluation(y_test, y_pred):\n",
    "    '''\n",
    "    to return metrics score\n",
    "\n",
    "    input:\n",
    "        y_test: input true label; type: pandas dataframe\n",
    "        y_pred: input prediction; type: pandas dataframe\n",
    "\n",
    "    output:\n",
    "        evaluation result; type: tuple\n",
    "    '''\n",
    "    ac = round(accuracy_score(y_test, y_pred), 4)\n",
    "    f1 = round(f1_score(y_test, y_pred), 4)\n",
    "    pre = round(precision_score(y_test, y_pred), 4)\n",
    "    rec = round(recall_score(y_test, y_pred), 4)\n",
    "    auc = round(roc_auc_score(y_test, y_pred), 4)\n",
    "    f_beta = round(fbeta_score(y_test, y_pred, beta=3), 4)\n",
    "\n",
    "    return ac, f1, pre, rec, auc, f_beta\n",
    "\n",
    "\n",
    "def basic_ml(using_model={'xgb': XGBClassifier(), 'rf': RandomForestClassifier()},\n",
    "             X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test):\n",
    "    '''\n",
    "    to return evaluate dataframe\n",
    "\n",
    "    input:\n",
    "        using_model: input using model; type: dictionary\n",
    "        x_train: input x_train; type: numpy.ndarray or dataframe\n",
    "        y_train: input y_train; type: numpy.ndarray or dataframe\n",
    "        x_test: input x_test; type: numpy.ndarray  or dataframe\n",
    "        y_test: input y_test; type: numpy.ndarray  or dataframe\n",
    "\n",
    "    output:\n",
    "        evaluate dataframe\n",
    "    '''\n",
    "    score = []\n",
    "    for i in using_model:\n",
    "        model = using_model[i]\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        score.append([i]+list(evaluation(y_test, y_pred)))\n",
    "    return pd.DataFrame(data=score, columns=['model', 'accuracy', 'f1_score', 'precision', 'recall', 'auc', 'f_beta'])\n",
    "\n",
    "\n",
    "df = basic_ml(using_model={'xgb': XGBClassifier(), 'rf': RandomForestClassifier(\n",
    ")}, X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, method='svm'):\n",
    "    if method == 'svm':\n",
    "        C = trial.suggest_loguniform('C', 1e-5, 1e5)\n",
    "        kernel = trial.suggest_categorical(\n",
    "            'kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
    "        degree = trial.suggest_int('degree', 2, 5)\n",
    "        clf = SVC(C=C, kernel=kernel, degree=degree)\n",
    "        clf.fit(X_train, y_train)\n",
    "    elif method == 'rf':\n",
    "        max_depth = trial.suggest_int(\"max_depth\", 2, 128)\n",
    "        min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 128)\n",
    "        max_leaf_nodes = int(trial.suggest_int(\"max_leaf_nodes\", 2, 128))\n",
    "        min_samples_leaf = int(trial.suggest_int('min_samples_leaf', 2, 128))\n",
    "        criterion = trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\"])\n",
    "        clf = RandomForestClassifier(min_samples_split=min_samples_split,\n",
    "                                     max_leaf_nodes=max_leaf_nodes,\n",
    "                                     criterion=criterion, random_state=4,\n",
    "                                     max_depth=max_depth, min_samples_leaf=min_samples_leaf)\n",
    "        clf.fit(X_train, y_train)\n",
    "    elif method == 'xgb':\n",
    "        max_depth = trial.suggest_int(\"max_depth\", 2, 128)\n",
    "        min_child_weight = trial.suggest_int(\"min_child_weight\", 2, 128)\n",
    "        gamma = trial.suggest_int(\"gamma\", 2, 128)\n",
    "        subsample = trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1)\n",
    "        colsample_bytree = trial.suggest_discrete_uniform(\n",
    "            'colsample_bytree', 0.5, 1, 0.1)\n",
    "        learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
    "\n",
    "        clf = XGBClassifier(max_depth=max_depth, min_child_weight=min_child_weight, gamma=gamma, subsample=subsample,\n",
    "                            colsample_bytree=colsample_bytree, learning_rate=learning_rate)\n",
    "        clf.fit(X_train, y_train)\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid method '{method}'\")\n",
    "    y_pred = clf.predict(X_val)\n",
    "    scores =fbeta_score(y_val, y_pred, beta=3)\n",
    "    return scores\n",
    "\n",
    "def study(method='xgb', n_trials=10):\n",
    "    study = optuna.create_study()\n",
    "    study.optimize(lambda trial: objective(trial, method='xgb'), n_trials=n_trials)\n",
    "    return study.best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-15 18:17:12,586]\u001b[0m A new study created in memory with name: no-name-435f6456-faa8-48d3-afeb-05d7d1a39833\u001b[0m\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_1860\\2356749840.py:24: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  subsample = trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_1860\\2356749840.py:25: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  colsample_bytree = trial.suggest_discrete_uniform(\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_1860\\2356749840.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "\u001b[32m[I 2023-05-15 18:17:12,699]\u001b[0m Trial 0 finished with value: 0.0 and parameters: {'max_depth': 120, 'min_child_weight': 107, 'gamma': 58, 'subsample': 1.0, 'colsample_bytree': 0.7, 'learning_rate': 1.0137435961873093e-05}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_1860\\2356749840.py:24: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  subsample = trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_1860\\2356749840.py:25: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  colsample_bytree = trial.suggest_discrete_uniform(\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_1860\\2356749840.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "\u001b[32m[I 2023-05-15 18:17:12,831]\u001b[0m Trial 1 finished with value: 0.0 and parameters: {'max_depth': 105, 'min_child_weight': 34, 'gamma': 2, 'subsample': 0.9, 'colsample_bytree': 1.0, 'learning_rate': 0.001284864895246024}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_1860\\2356749840.py:24: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  subsample = trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_1860\\2356749840.py:25: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  colsample_bytree = trial.suggest_discrete_uniform(\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_1860\\2356749840.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "\u001b[32m[I 2023-05-15 18:17:12,976]\u001b[0m Trial 2 finished with value: 0.0 and parameters: {'max_depth': 36, 'min_child_weight': 67, 'gamma': 29, 'subsample': 0.5, 'colsample_bytree': 0.6, 'learning_rate': 0.0012780741275920209}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_1860\\2356749840.py:24: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  subsample = trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_1860\\2356749840.py:25: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  colsample_bytree = trial.suggest_discrete_uniform(\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_1860\\2356749840.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "\u001b[32m[I 2023-05-15 18:17:13,081]\u001b[0m Trial 3 finished with value: 0.0 and parameters: {'max_depth': 60, 'min_child_weight': 60, 'gamma': 51, 'subsample': 1.0, 'colsample_bytree': 0.6, 'learning_rate': 0.009110862514300136}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_1860\\2356749840.py:24: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  subsample = trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_1860\\2356749840.py:25: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  colsample_bytree = trial.suggest_discrete_uniform(\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_1860\\2356749840.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "\u001b[32m[I 2023-05-15 18:17:13,187]\u001b[0m Trial 4 finished with value: 0.0 and parameters: {'max_depth': 43, 'min_child_weight': 54, 'gamma': 65, 'subsample': 0.9, 'colsample_bytree': 1.0, 'learning_rate': 6.406624971772723e-05}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_1860\\2356749840.py:24: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  subsample = trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_1860\\2356749840.py:25: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  colsample_bytree = trial.suggest_discrete_uniform(\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_1860\\2356749840.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "\u001b[32m[I 2023-05-15 18:17:13,277]\u001b[0m Trial 5 finished with value: 0.0 and parameters: {'max_depth': 14, 'min_child_weight': 113, 'gamma': 110, 'subsample': 0.5, 'colsample_bytree': 0.7, 'learning_rate': 0.0007163068334482624}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_1860\\2356749840.py:24: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  subsample = trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_1860\\2356749840.py:25: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  colsample_bytree = trial.suggest_discrete_uniform(\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_1860\\2356749840.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "\u001b[32m[I 2023-05-15 18:17:13,380]\u001b[0m Trial 6 finished with value: 0.0 and parameters: {'max_depth': 75, 'min_child_weight': 47, 'gamma': 36, 'subsample': 0.6, 'colsample_bytree': 0.9, 'learning_rate': 0.00014092223126089493}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_1860\\2356749840.py:24: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  subsample = trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_1860\\2356749840.py:25: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  colsample_bytree = trial.suggest_discrete_uniform(\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_1860\\2356749840.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "\u001b[32m[I 2023-05-15 18:17:13,476]\u001b[0m Trial 7 finished with value: 0.0 and parameters: {'max_depth': 36, 'min_child_weight': 53, 'gamma': 53, 'subsample': 0.7, 'colsample_bytree': 0.9, 'learning_rate': 6.017155678173792e-05}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_1860\\2356749840.py:24: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  subsample = trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_1860\\2356749840.py:25: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  colsample_bytree = trial.suggest_discrete_uniform(\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_1860\\2356749840.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "\u001b[32m[I 2023-05-15 18:17:13,608]\u001b[0m Trial 8 finished with value: 0.0 and parameters: {'max_depth': 119, 'min_child_weight': 20, 'gamma': 122, 'subsample': 0.5, 'colsample_bytree': 0.6, 'learning_rate': 0.0008983631482415347}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_1860\\2356749840.py:24: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  subsample = trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.1)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_1860\\2356749840.py:25: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  colsample_bytree = trial.suggest_discrete_uniform(\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_1860\\2356749840.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "\u001b[32m[I 2023-05-15 18:17:13,726]\u001b[0m Trial 9 finished with value: 0.0 and parameters: {'max_depth': 15, 'min_child_weight': 105, 'gamma': 67, 'subsample': 0.6, 'colsample_bytree': 0.5, 'learning_rate': 0.0002195711075904746}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "c:\\Users\\User\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>auc</th>\n",
       "      <th>f_beta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xgb1</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.6512</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.5185</td>\n",
       "      <td>0.7535</td>\n",
       "      <td>0.5405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  accuracy  f1_score  precision  recall     auc  f_beta\n",
       "0   xgb     0.865    0.0000      0.000  0.0000  0.5000  0.0000\n",
       "1  xgb1     0.925    0.6512      0.875  0.5185  0.7535  0.5405"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_ml(using_model={'xgb': XGBClassifier(**study(method='rf', n_trials=10)),'xgb1':XGBClassifier()},\n",
    " X_train=pd.concat([X_train, X_val], axis=0), y_train=pd.concat([y_train, y_val], axis=0), \n",
    " X_test=X_test, y_test=y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
